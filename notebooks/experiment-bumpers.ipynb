{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /mnt/anaconda2/envs/py36/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /mnt/anaconda2/envs/py36/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.11.3 in /mnt/anaconda2/envs/py36/lib/python3.6/site-packages (from opencv-python)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scipy in /mnt/anaconda2/envs/py36/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm\n",
    "! pip install opencv-python\n",
    "! pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pickle\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import scipy.ndimage\n",
    "import itertools, operator\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Divorce\": {\n",
      "    \"S3\": {\n",
      "      \"E1\": \"217394H1_Divorce_S3_E1.mxf.mp4\",\n",
      "      \"E3\": \"217396H1_Divorce_S3_E3.mxf.mp4\",\n",
      "      \"E2\": \"217395H1_Divorce_S3_E2.mxf.mp4\"\n",
      "    },\n",
      "    \"S2\": {\n",
      "      \"E2\": \"208888H1_Divorce_S2_E2.mxf.mp4\",\n",
      "      \"E3\": \"208889H1_Divorce_S2_E3.mxf.mp4\",\n",
      "      \"E1\": \"208887H1_Divorce_S2_E1.mxf.mp4\"\n",
      "    },\n",
      "    \"S1\": {\n",
      "      \"E1\": \"193757H1_Divorce_S1_E1.mxf.mp4\",\n",
      "      \"E3\": \"193917H1_Divorce_S1_E3.mxf.mp4\",\n",
      "      \"E2\": \"193916H1_Divorce_S1_E2.mxf.mp4\"\n",
      "    }\n",
      "  },\n",
      "  \"Expeditie_Robinson\": {\n",
      "    \"S11\": {\n",
      "      \"E2\": \"226558H1_Expeditie_Robinson_S11_E2.mxf.mp4\",\n",
      "      \"E3\": \"226559H1_Expeditie_Robinson_S11_E3.mxf.mp4\",\n",
      "      \"E1\": \"226557H1_Expeditie_Robinson_S11_E1.mxf.mp4\"\n",
      "    },\n",
      "    \"S13\": {\n",
      "      \"E1\": \"251218H1_Expeditie_Robinson_S13_E1.mxf.mp4\",\n",
      "      \"E2\": \"250463H1_Expeditie_Robinson_S13_E2.mxf.mp4\"\n",
      "    },\n",
      "    \"S14\": {\n",
      "      \"E3\": \"260888H1_Expeditie_Robinson_S14_E3.mxf.mp4\",\n",
      "      \"E1\": \"262135H1_Expeditie_Robinson_S14_E1.mxf.mp4\",\n",
      "      \"E2\": \"262136H1_Expeditie_Robinson_S14_E2.mxf.mp4\"\n",
      "    },\n",
      "    \"S10\": {\n",
      "      \"E3\": \"214790A1_Expeditie_Robinson_S10_E3.mxf.mp4\",\n",
      "      \"E2\": \"214789B1_Expeditie_Robinson_S10_E2.mxf.mp4\",\n",
      "      \"E1\": \"214579A1_Expeditie_Robinson_S10_E1.mxf.mp4\"\n",
      "    }\n",
      "  },\n",
      "  \"Temptation_Island\": {\n",
      "    \"S4\": {\n",
      "      \"E5\": \"265708H1_Temptation_Island_S4_E5_high.mp4\",\n",
      "      \"E3\": \"266844H1_Temptation_Island_S4_E3_high.mp4\",\n",
      "      \"E6\": \"265709H1_Temptation_Island_S4_E6_high.mp4\",\n",
      "      \"E2\": \"266843H1_Temptation_Island_S4_E2_high.mp4\",\n",
      "      \"E4\": \"265707H1_Temptation_Island_S4_E4_high.mp4\",\n",
      "      \"E8\": \"265711H1_Temptation_Island_S4_E8_high.mp4\",\n",
      "      \"E7\": \"265710H1_Temptation_Island_S4_E7_high.mp4\",\n",
      "      \"E1\": \"266841H1_Temptation_Island_S4_E1_high.mp4\",\n",
      "      \"E9\": \"265712H1_Temptation_Island_S4_E9_high.mp4\"\n",
      "    }\n",
      "  },\n",
      "  \"How_Its_Done\": {\n",
      "    \"S3\": {\n",
      "      \"E3\": \"266185H1_How_Its_Done_S3_E3_high.mp4\",\n",
      "      \"E5\": \"266187H1_How_Its_Done_S3_E5_high.mp4\",\n",
      "      \"E4\": \"266186H1_How_Its_Done_S3_E4_high.mp4\",\n",
      "      \"E6\": \"266188H1_How_Its_Done_S3_E6_high.mp4\",\n",
      "      \"E2\": \"266184H1_How_Its_Done_S3_E2_high.mp4\",\n",
      "      \"E1\": \"266537H1_How_Its_Done_S3_E1_high.mp4\"\n",
      "    }\n",
      "  },\n",
      "  \"Judas\": {\n",
      "    \"S1\": {\n",
      "      \"E5\": \"263781H1_Judas_S1_E5_high.mp4\",\n",
      "      \"E4\": \"263780H1_Judas_S1_E4_high.mp4\",\n",
      "      \"E6\": \"263782H1_Judas_S1_E6_high.mp4\",\n",
      "      \"E3\": \"263779H1_Judas_S1_E3_high.mp4\",\n",
      "      \"E1\": \"263777H1_Judas_S1_E1_high.mp4\",\n",
      "      \"E2\": \"263778H1_Judas_S1_E2_high.mp4\"\n",
      "    }\n",
      "  },\n",
      "  \"Familie_Kruys\": {\n",
      "    \"S1\": {\n",
      "      \"E2\": \"219120H1_Familie_Kruys_S1_E2_VOD.mxf.mp4\",\n",
      "      \"E3\": \"219121H1_Familie_Kruys_S1_E3_VOD.mxf.mp4\",\n",
      "      \"E1\": \"219119H1_Familie_Kruys_S1_E1_VOD.mxf.mp4\"\n",
      "    },\n",
      "    \"S4\": {\n",
      "      \"E2\": \"261246H1_Familie_Kruys_S4_E2.mxf.mp4\",\n",
      "      \"E1\": \"261245H1_Familie_Kruys_S4_E1.mxf.mp4\",\n",
      "      \"E3\": \"261247H1_Familie_Kruys_S4_E3.mxf.mp4\"\n",
      "    }\n",
      "  },\n",
      "  \"Raveleijn\": {\n",
      "    \"S1\": {\n",
      "      \"E11\": \"263279H1_Raveleijn_S1_E11_high.mp4\",\n",
      "      \"E10\": \"263278H1_Raveleijn_S1_E10_high.mp4\",\n",
      "      \"E1\": \"263269H1_Raveleijn_S1_E1_high.mp4\",\n",
      "      \"E9\": \"263277H1_Raveleijn_S1_E9_high.mp4\",\n",
      "      \"E5\": \"263273H1_Raveleijn_S1_E5_high.mp4\",\n",
      "      \"E12\": \"263280H1_Raveleijn_S1_E12_high.mp4\",\n",
      "      \"E3\": \"263271H1_Raveleijn_S1_E3_high.mp4\",\n",
      "      \"E7\": \"263275H1_Raveleijn_S1_E7_high.mp4\",\n",
      "      \"E2\": \"263270H1_Raveleijn_S1_E2_high.mp4\",\n",
      "      \"E6\": \"263274H1_Raveleijn_S1_E6_high.mp4\",\n",
      "      \"E4\": \"263272H1_Raveleijn_S1_E4_high.mp4\",\n",
      "      \"E8\": \"263276H1_Raveleijn_S1_E8_high.mp4\"\n",
      "    }\n",
      "  },\n",
      "  \"Het_Italiaanse_Dorp\": {\n",
      "    \"S1\": {\n",
      "      \"E2\": \"258520H1_Het_Italiaanse_Dorp_S1_E2.mxf.mp4\",\n",
      "      \"E1\": \"258519H1_Het_Italiaanse_Dorp_S1_E1.mxf.mp4\"\n",
      "    }\n",
      "  },\n",
      "  \"Meisje_Van_Plezier\": {\n",
      "    \"S1\": {\n",
      "      \"E2\": \"245406H1_Meisje_Van_Plezier_S1_E2.mxf.mp4\",\n",
      "      \"E3\": \"245407H1_Meisje_Van_Plezier_S1_E3.mxf.mp4\",\n",
      "      \"E1\": \"245405H1_Meisje_Van_Plezier_S1_E1.mxf.mp4\"\n",
      "    }\n",
      "  },\n",
      "  \"Herman_Tegen_De_Rest\": {\n",
      "    \"S1\": {\n",
      "      \"E3\": \"266162H1_Herman_Tegen_De_Rest_S1_E3_high.mp4\",\n",
      "      \"E1\": \"266160H1_Herman_Tegen_De_Rest_S1_E1_high.mp4\",\n",
      "      \"E4\": \"266163H1_Herman_Tegen_De_Rest_S1_E4_high.mp4\",\n",
      "      \"E2\": \"266161H1_Herman_Tegen_De_Rest_S1_E2_high.mp4\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      " Total of 68 files\n"
     ]
    }
   ],
   "source": [
    "files = [f for f in os.listdir('videos') if isfile(join('videos', f))]\n",
    "\n",
    "shows = {}\n",
    "for file in files:\n",
    "    fullname = file.split('/')[-1]\n",
    "    fn = fullname.replace('_VOD','').replace('_high','')\n",
    "    fn_split = fn.split('_')\n",
    "    \n",
    "    name = \"_\".join(fn_split[1:-2])\n",
    "    season = fn_split[-2]\n",
    "    episode = fn_split[-1].split('.')[0]\n",
    "    \n",
    "#     print(\"name: {}, season: {}, episode: {}\".format(name, season, episode))\n",
    "    \n",
    "    if name not in shows:\n",
    "        shows[name] = {season : {episode : fullname}}\n",
    "    \n",
    "    if season not in shows[name]:\n",
    "        shows[name][season] = {episode : fullname}\n",
    "        \n",
    "    if episode not in shows[name][season]:\n",
    "        shows[name][season][episode] = fullname\n",
    "\n",
    "    \n",
    "print(json.dumps(shows, indent=2))\n",
    "print(\"\\n Total of {} files\".format(len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def fill_gaps(sequence, lookahead):\n",
    "    \"\"\"\n",
    "    Function that replaces 0's with 1's in an array consisting of only 0's and 1's,\n",
    "    if the gap between the next 1 is smaller than the lookahead.\n",
    "    \n",
    "    Example: \n",
    "        [0,1,0,0,0,1,0] as input with lookahead = 4\n",
    "        outputs [0,1,1,1,1,1,0], the gap between 1's is filled        \n",
    "    \"\"\"\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(sequence) - lookahead:\n",
    "        current = sequence[i]\n",
    "        next = sequence[i + 1 : i + lookahead].tolist()\n",
    "        \n",
    "        if current and True in next:\n",
    "            x = 0\n",
    "            while not next[x]:\n",
    "                sequence[i + 1 + x] = True\n",
    "                x = x + 1\n",
    "                \n",
    "        i = i + 1\n",
    "\n",
    "    return sequence\n",
    "\n",
    "def to_time_string(seconds):\n",
    "    \"\"\"\n",
    "    Given seconds in number, returns a string in the format hh:mm:ss (example: 01:30:45)\n",
    "    \"\"\"\n",
    "    return str(datetime.timedelta(seconds=seconds))\n",
    "\n",
    "\n",
    "def overlap(first_inter,second_inter):\n",
    "    for f,s in ((first_inter,second_inter), (second_inter,first_inter)):\n",
    "        #will check both ways\n",
    "        for time in (f[0], f[1]):\n",
    "            if s[0] <= time <= s[1]:\n",
    "                return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "t1 = (0,10)\n",
    "t2 = (7,15)\n",
    "t3 = (15,20)\n",
    "t4 = (50,60)\n",
    "\n",
    "print(overlap(t1,t2))\n",
    "print(overlap(t2,t3))\n",
    "print(overlap(t3,t4))\n",
    "\n",
    "def to_seconds(time):\n",
    "    \"\"\"\n",
    "    Converts string of format hh:mm:ss to total number of seconds\n",
    "    \"\"\"\n",
    "    if time == 'None':\n",
    "        return -1\n",
    "    try:\n",
    "        hours = int(time.split(\":\")[0])\n",
    "        minutes = int(time.split(\":\")[1])\n",
    "        seconds = int(float(time.split(\":\")[2]))\n",
    "        return hours*60*60 + minutes * 60 + seconds\n",
    "    except:\n",
    "#         print(time)\n",
    "        if math.isnan(time):\n",
    "            return -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(657, 671), (1981, 1993), (3104, 3118)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_bumper_timestamps_by_filename(filename, df):\n",
    "    result = []\n",
    "    row = df.loc[df['filename'] == filename].to_dict(orient='records')[0]\n",
    "    if isinstance(row['start1'], str):\n",
    "        result.append((row['start1'], row['end1']))\n",
    "    if isinstance(row['start2'], str):\n",
    "        result.append((row['start2'], row['end2']))\n",
    "    if isinstance(row['start3'], str):\n",
    "        result.append((row['start3'], row['end3']))\n",
    "    if isinstance(row['start4'], str):\n",
    "        result.append((row['start4'], row['end4']))\n",
    "        \n",
    "    result_final = []\n",
    "    for start, end in result:\n",
    "        result_final.append((to_seconds(start), to_seconds(end)))\n",
    "    \n",
    "    \n",
    "    return result_final\n",
    "\n",
    "annotations = pd.read_csv(\"annotations_bumpers.csv\").dropna(how='all')\n",
    "annotations.head()\n",
    "\n",
    "get_bumper_timestamps_by_filename('214789B1_Expeditie_Robinson_S10_E2.mxf.mp4', annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['214579A1_Expeditie_Robinson_S10_E1.mxf.mp4',\n",
       " '214789B1_Expeditie_Robinson_S10_E2.mxf.mp4',\n",
       " '214790A1_Expeditie_Robinson_S10_E3.mxf.mp4',\n",
       " '226557H1_Expeditie_Robinson_S11_E1.mxf.mp4',\n",
       " '226558H1_Expeditie_Robinson_S11_E2.mxf.mp4',\n",
       " '226559H1_Expeditie_Robinson_S11_E3.mxf.mp4',\n",
       " '250463H1_Expeditie_Robinson_S13_E2.mxf.mp4',\n",
       " '251218H1_Expeditie_Robinson_S13_E1.mxf.mp4',\n",
       " '260888H1_Expeditie_Robinson_S14_E3.mxf.mp4',\n",
       " '262135H1_Expeditie_Robinson_S14_E1.mxf.mp4',\n",
       " '262136H1_Expeditie_Robinson_S14_E2.mxf.mp4',\n",
       " '265707H1_Temptation_Island_S4_E4_high.mp4',\n",
       " '265708H1_Temptation_Island_S4_E5_high.mp4',\n",
       " '265709H1_Temptation_Island_S4_E6_high.mp4',\n",
       " '265710H1_Temptation_Island_S4_E7_high.mp4',\n",
       " '265711H1_Temptation_Island_S4_E8_high.mp4',\n",
       " '265712H1_Temptation_Island_S4_E9_high.mp4',\n",
       " '266841H1_Temptation_Island_S4_E1_high.mp4',\n",
       " '266843H1_Temptation_Island_S4_E2_high.mp4',\n",
       " '266844H1_Temptation_Island_S4_E3_high.mp4']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes = [v for v in shows[\"Temptation_Island\"][\"S4\"].values()]\n",
    "episodes = episodes + [v for v in shows[\"Expeditie_Robinson\"][\"S10\"].values()]\n",
    "episodes = episodes + [v for v in shows[\"Expeditie_Robinson\"][\"S11\"].values()]\n",
    "episodes = episodes + [v for v in shows[\"Expeditie_Robinson\"][\"S13\"].values()]\n",
    "episodes = episodes + [v for v in shows[\"Expeditie_Robinson\"][\"S14\"].values()]\n",
    "episodes=sorted(episodes)\n",
    "episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ece26ba263f4e1ebed452c132da3475"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:68: RuntimeWarning: invalid value encountered in true_divide\n",
      "/mnt/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results ./videos_resized_w320/colortexturemoments_framejump3/, ratio = 0.5\n",
      "Total precision:\t 0.145\n",
      "Total recall:\t 0.542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deedcf1b7e2d4106a88f8c2a18d30009"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results ./videos_resized_w320/colortexturemoments_framejump3/, ratio = 0.6\n",
      "Total precision:\t 0.089\n",
      "Total recall:\t 0.667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b76426536f84f0ab09bb1f589803f55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results ./videos_resized_w320/colortexturemoments_framejump3/, ratio = 0.7\n",
      "Total precision:\t 0.072\n",
      "Total recall:\t 0.833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e06805aa394a7bbdd3cc7a3cdc6e54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results ./videos_resized_w320/colortexturemoments_framejump3/, ratio = 0.8\n",
      "Total precision:\t 0.072\n",
      "Total recall:\t 0.958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920e9249ee304f2eb99ede3e90994007"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results ./videos_resized_w224/histogram_of_gradient_framejump3/, ratio = 0.5\n",
      "Total precision:\t 0.611\n",
      "Total recall:\t 0.917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c144b9455bb45c39eddc7a9148b5910"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results ./videos_resized_w224/histogram_of_gradient_framejump3/, ratio = 0.6\n",
      "Total precision:\t 0.484\n",
      "Total recall:\t 0.938\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963e15de6e2242b29cd22ac43221c8ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results ./videos_resized_w224/histogram_of_gradient_framejump3/, ratio = 0.7\n",
      "Total precision:\t 0.288\n",
      "Total recall:\t 0.979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d10bbdd50c476f96bd93a5f9818866"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results ./videos_resized_w224/histogram_of_gradient_framejump3/, ratio = 0.8\n",
      "Total precision:\t 0.081\n",
      "Total recall:\t 0.979\n"
     ]
    }
   ],
   "source": [
    "# vectors_dir = \"./videos/full_histograms_binsize30_framejump3/\"\n",
    "# vectors_dir = \"./videos_resized_w224/histogram_of_gradient_framejump3/\"\n",
    "# vectors_dir = \"./videos_resized_w320/colortexturemoments_framejump3/\"\n",
    "vectors_dir = \"./videos_resized_w320/color_histogram_binsize180_framejump3/\"\n",
    "\n",
    "vectors = [\n",
    "#     \"./videos_resized_w320/color_histogram_binsize180_framejump3/\",\n",
    "    \"./videos_resized_w320/colortexturemoments_framejump3/\",\n",
    "    \"./videos_resized_w224/histogram_of_gradient_framejump3/\"\n",
    "          ]\n",
    "\n",
    "verbose = False\n",
    "\n",
    "for dir in vectors:\n",
    "    for ratio in [0.5, 0.6, 0.7, 0.8]:\n",
    "\n",
    "        vector_files = [dir+e+'.p' for e in episodes]\n",
    "\n",
    "        histograms = []\n",
    "        lengths = []\n",
    "\n",
    "        for f in vector_files:\n",
    "            h = np.array(pickle.load(open(f, \"rb\")), np.float32)\n",
    "            lengths.append(h.shape[0])\n",
    "            histograms.append(h)\n",
    "\n",
    "    #     print(histograms[0].shape)\n",
    "        # histograms = np.vstack(histograms)\n",
    "        # print(lengths)\n",
    "        # histograms.shape\n",
    "        total_overlap = 0\n",
    "        total_detections = 0\n",
    "        total_ground_truth = 0\n",
    "        plot = False\n",
    "\n",
    "        for episode_index in tqdm(range(0, len(episodes))):\n",
    "        #     episode_index = ix\n",
    "            if verbose:\n",
    "                print(\"Detecting bumpers for: {}\".format(episodes[episode_index]))\n",
    "            histogram = histograms[episode_index]\n",
    "\n",
    "            stepsize = 167\n",
    "            s = 0\n",
    "            e = stepsize\n",
    "            result = np.empty(0)\n",
    "            result_non_ratio = np.empty(0)\n",
    "\n",
    "            for i in range(0, len(histogram) - 2*stepsize, stepsize):\n",
    "                s = i\n",
    "                e = i + stepsize\n",
    "            #     print(\"start: {}, end: {}\".format(s,e))\n",
    "                q = histogram[s:e]\n",
    "            #     rest = np.append(histogram[:s], histogram[e:], axis=0)\n",
    "                rest = histogram[e + 3*stepsize:]\n",
    "\n",
    "                vector_size = q.shape[1]\n",
    "                # build the index, set vector size\n",
    "            #     print(\"Building index with size: {}\".format(rest.shape[0]))\n",
    "                index = faiss.IndexFlatL2(vector_size)    \n",
    "                # add vectors to the index\n",
    "                index.add(rest)\n",
    "\n",
    "                # we want to see k nearest neighbors\n",
    "                k = 2\n",
    "                # search with for matches with q\n",
    "                scores, indexes = index.search(q, k)\n",
    "\n",
    "                r = scores[:,0] / scores[:,1]\n",
    "                r_nonratio = scores[:,0]\n",
    "\n",
    "                result = np.concatenate((result, r))\n",
    "                result_non_ratio = np.concatenate((result_non_ratio, r_nonratio))\n",
    "\n",
    "            gap_fill = 150 \n",
    "\n",
    "            # result_non_ratio = scipy.ndimage.median_filter(result_non_ratio, 10)\n",
    "            if plot:\n",
    "                plt.plot(result_non_ratio)\n",
    "                plt.ylim(0,0.2)\n",
    "                plt.show()\n",
    "\n",
    "                # result = scipy.ndimage.median_filter(result, 10)\n",
    "                plt.plot(result)\n",
    "                plt.show()\n",
    "\n",
    "                plt.plot(result < ratio)\n",
    "                plt.show()\n",
    "\n",
    "                plt.plot(fill_gaps(result < ratio, gap_fill))\n",
    "                plt.show()\n",
    "\n",
    "            below_threshold = fill_gaps(result < ratio, gap_fill)\n",
    "            nonzeros = [[i for i,value in it] for key, it in itertools.groupby(enumerate(below_threshold), key=operator.itemgetter(1)) if key != 0]\n",
    "            framejump = 3\n",
    "\n",
    "            relevant = 0\n",
    "            total = 0\n",
    "            ground_truths = get_bumper_timestamps_by_filename(episodes[episode_index], annotations)\n",
    "\n",
    "            for n in nonzeros:\n",
    "                start = n[0]\n",
    "                end = n[-1]\n",
    "                if end - start > (2.5 * 25 / framejump): #only count when larger than x seconds \n",
    "\n",
    "                    total += 1\n",
    "                    start_seconds = start / (25 / framejump)\n",
    "                    end_seconds = end / (25 / framejump)\n",
    "\n",
    "                    if verbose:\n",
    "                        print(to_time_string(start_seconds))\n",
    "                        print(to_time_string(end_seconds))\n",
    "\n",
    "                    total_detections += 1\n",
    "                    for gt in ground_truths:\n",
    "                        if overlap(gt , (start_seconds, end_seconds)):\n",
    "                            if verbose:\n",
    "                                print(\"Overlap!\")\n",
    "                            relevant += 1\n",
    "                            total_overlap += 1\n",
    "\n",
    "            total_ground_truth += len(ground_truths)\n",
    "\n",
    "            if verbose:\n",
    "                if total > 0:\n",
    "                    print(\"precision: \\t{}\".format(relevant / total))\n",
    "                print(ground_truths)\n",
    "                print(\"recall: \\t\\t{}\".format(relevant / len(ground_truths)))\n",
    "                print()\n",
    "                print(\"======================================================================\")\n",
    "\n",
    "        total_precision = total_overlap / total_detections\n",
    "        total_recall = total_overlap / total_ground_truth\n",
    "        f1 = (2*total_precision*total_recall) / (total_precision + total_recall)\n",
    "\n",
    "        print(\"Results {}, ratio = {}\".format(dir, ratio))\n",
    "        print(\"Total precision:\\t {0:.3f}\".format(total_precision))\n",
    "        print(\"Total recall:\\t {0:.3f}\".format(total_recall))\n",
    "#         print(\"F1:\\t {0:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
